# âš™ï¸ é…ç½®ç®¡ç†å’Œéƒ¨ç½²æŒ‡å—

> Telegram Bot é…ç½®ç®¡ç†ã€ç¯å¢ƒéƒ¨ç½²å’Œè¿ç»´ç›‘æ§çš„å®Œæ•´æŒ‡å—

## ğŸ“‹ ç›®å½•

- [é…ç½®ç®¡ç†ç³»ç»Ÿ](#é…ç½®ç®¡ç†ç³»ç»Ÿ)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [Docker å®¹å™¨åŒ–](#docker-å®¹å™¨åŒ–)
- [CI/CD è‡ªåŠ¨åŒ–](#cicd-è‡ªåŠ¨åŒ–)
- [è´Ÿè½½å‡è¡¡å’Œæ‰©å±•](#è´Ÿè½½å‡è¡¡å’Œæ‰©å±•)
- [ç›‘æ§å’Œå‘Šè­¦](#ç›‘æ§å’Œå‘Šè­¦)
- [å¤‡ä»½å’Œæ¢å¤](#å¤‡ä»½å’Œæ¢å¤)
- [è¿ç»´æœ€ä½³å®è·µ](#è¿ç»´æœ€ä½³å®è·µ)

## ğŸ¯ é…ç½®ç®¡ç†ç³»ç»Ÿ

### åŠ¨æ€é…ç½®æ¶æ„

```mermaid
graph TB
    A[ç¯å¢ƒå˜é‡] --> B[é…ç½®æœåŠ¡]
    C[æ•°æ®åº“é…ç½®] --> B
    D[Redisç¼“å­˜] --> B
    B --> E[Boté…ç½®]
    B --> F[ç½‘ç»œé…ç½®]
    B --> G[æ”¯ä»˜é…ç½®]
    E --> H[TelegramBotService]
    F --> I[TronService]
    G --> J[PaymentService]
    
    K[ç®¡ç†é¢æ¿] --> B
    L[é…ç½®çƒ­æ›´æ–°] --> B
```

### é¡¹ç›®é…ç½®ç³»ç»Ÿ

```typescript
// config/ConfigManager.ts
export class ConfigManager {
  private static instance: ConfigManager;
  private config: Map<string, any> = new Map();
  private watchers: Map<string, Function[]> = new Map();

  static getInstance(): ConfigManager {
    if (!this.instance) {
      this.instance = new ConfigManager();
    }
    return this.instance;
  }

  /**
   * åˆå§‹åŒ–é…ç½®ç³»ç»Ÿ
   */
  async initialize(): Promise<void> {
    try {
      console.log('ğŸ”§ Initializing configuration system...');

      // åŠ è½½ç¯å¢ƒé…ç½®
      await this.loadEnvironmentConfig();
      
      // åŠ è½½æ•°æ®åº“é…ç½®
      await this.loadDatabaseConfig();
      
      // è®¾ç½®é…ç½®ç›‘å¬
      await this.setupConfigWatcher();
      
      // éªŒè¯å¿…è¦é…ç½®
      await this.validateRequiredConfig();

      console.log('âœ… Configuration system initialized successfully');
    } catch (error) {
      console.error('âŒ Configuration initialization failed:', error);
      throw error;
    }
  }

  /**
   * åŠ è½½ç¯å¢ƒé…ç½®
   */
  private async loadEnvironmentConfig(): Promise<void> {
    const envConfig = {
      // åº”ç”¨åŸºç¡€é…ç½®
      NODE_ENV: process.env.NODE_ENV || 'development',
      PORT: parseInt(process.env.PORT || '3001'),
      API_VERSION: process.env.API_VERSION || 'v1',
      
      // æ•°æ®åº“é…ç½®
      DATABASE_URL: process.env.DATABASE_URL,
      DB_HOST: process.env.DB_HOST || 'localhost',
      DB_PORT: parseInt(process.env.DB_PORT || '5432'),
      DB_NAME: process.env.DB_NAME || 'tron_energy_rental',
      DB_USER: process.env.DB_USER || 'postgres',
      DB_PASSWORD: process.env.DB_PASSWORD,
      
      // Redis é…ç½®
      REDIS_URL: process.env.REDIS_URL || 'redis://localhost:6379',
      REDIS_PASSWORD: process.env.REDIS_PASSWORD,
      
      // Telegram é…ç½®
      TELEGRAM_BOT_TOKEN: process.env.TELEGRAM_BOT_TOKEN,
      TELEGRAM_WEBHOOK_URL: process.env.TELEGRAM_WEBHOOK_URL,
      TELEGRAM_WEBHOOK_SECRET: process.env.TELEGRAM_WEBHOOK_SECRET,
      
      // TRON é…ç½®
      TRON_NETWORK: process.env.TRON_NETWORK || 'mainnet',
      TRON_API_KEY: process.env.TRON_API_KEY,
      TRON_PRIVATE_KEY: process.env.TRON_PRIVATE_KEY,
      TRON_PAYMENT_ADDRESS: process.env.TRON_PAYMENT_ADDRESS,
      
      // å®‰å…¨é…ç½®
      JWT_SECRET: process.env.JWT_SECRET,
      ENCRYPTION_KEY: process.env.ENCRYPTION_KEY,
      
      // æ—¥å¿—é…ç½®
      LOG_LEVEL: process.env.LOG_LEVEL || 'info',
      LOG_FILE: process.env.LOG_FILE || 'logs/app.log',
      
      // æœåŠ¡é…ç½®
      RATE_LIMIT: parseInt(process.env.RATE_LIMIT || '100'),
      SESSION_TIMEOUT: parseInt(process.env.SESSION_TIMEOUT || '1800000'),
      
      // ä¸šåŠ¡é…ç½®
      DEFAULT_ENERGY_PRICE: parseFloat(process.env.DEFAULT_ENERGY_PRICE || '0.00001'),
      MIN_ORDER_AMOUNT: parseFloat(process.env.MIN_ORDER_AMOUNT || '1'),
      MAX_ORDER_AMOUNT: parseFloat(process.env.MAX_ORDER_AMOUNT || '10000'),
      
      // ç›‘æ§é…ç½®
      HEALTH_CHECK_INTERVAL: parseInt(process.env.HEALTH_CHECK_INTERVAL || '60000'),
      METRICS_ENABLED: process.env.METRICS_ENABLED === 'true'
    };

    // å­˜å‚¨ç¯å¢ƒé…ç½®
    for (const [key, value] of Object.entries(envConfig)) {
      this.config.set(key, value);
    }
  }

  /**
   * åŠ è½½æ•°æ®åº“é…ç½®
   */
  private async loadDatabaseConfig(): Promise<void> {
    try {
      // åŠ è½½ç³»ç»Ÿé…ç½®è¡¨ä¸­çš„é…ç½®
      const dbConfigs = await db.systemConfig.findMany({
        where: { is_active: true }
      });

      for (const config of dbConfigs) {
        this.config.set(config.config_key, JSON.parse(config.config_value));
      }

      // åŠ è½½ Telegram Bot é…ç½®
      const botConfigs = await db.telegramBot.findMany({
        where: { is_active: true },
        include: { networks: true }
      });

      this.config.set('telegram_bots', botConfigs);

      // åŠ è½½ TRON ç½‘ç»œé…ç½®
      const networkConfigs = await db.tronNetwork.findMany({
        where: { is_active: true }
      });

      this.config.set('tron_networks', networkConfigs);

    } catch (error) {
      console.error('Failed to load database config:', error);
      // åœ¨æ•°æ®åº“ä¸å¯ç”¨æ—¶ä½¿ç”¨é»˜è®¤é…ç½®
    }
  }

  /**
   * è®¾ç½®é…ç½®ç›‘å¬
   */
  private async setupConfigWatcher(): Promise<void> {
    // ç›‘å¬æ•°æ®åº“é…ç½®å˜æ›´
    setInterval(async () => {
      try {
        const changes = await this.detectConfigChanges();
        if (changes.length > 0) {
          await this.applyConfigChanges(changes);
        }
      } catch (error) {
        console.error('Config watcher error:', error);
      }
    }, 30000); // æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
  }

  /**
   * éªŒè¯å¿…è¦é…ç½®
   */
  private async validateRequiredConfig(): Promise<void> {
    const required = [
      'TELEGRAM_BOT_TOKEN',
      'DATABASE_URL',
      'TRON_API_KEY',
      'JWT_SECRET'
    ];

    const missing = required.filter(key => !this.config.get(key));
    
    if (missing.length > 0) {
      throw new Error(`Missing required configuration: ${missing.join(', ')}`);
    }
  }

  /**
   * è·å–é…ç½®å€¼
   */
  get<T>(key: string, defaultValue?: T): T {
    return this.config.get(key) ?? defaultValue;
  }

  /**
   * è®¾ç½®é…ç½®å€¼
   */
  set(key: string, value: any): void {
    this.config.set(key, value);
    this.notifyWatchers(key, value);
  }

  /**
   * ç›‘å¬é…ç½®å˜æ›´
   */
  watch(key: string, callback: (value: any) => void): void {
    if (!this.watchers.has(key)) {
      this.watchers.set(key, []);
    }
    this.watchers.get(key)!.push(callback);
  }

  /**
   * é€šçŸ¥ç›‘å¬è€…
   */
  private notifyWatchers(key: string, value: any): void {
    const callbacks = this.watchers.get(key) || [];
    callbacks.forEach(callback => {
      try {
        callback(value);
      } catch (error) {
        console.error(`Config watcher error for ${key}:`, error);
      }
    });
  }

  /**
   * çƒ­æ›´æ–°é…ç½®
   */
  async hotReload(configKey: string, newValue: any): Promise<void> {
    try {
      // æ›´æ–°æ•°æ®åº“
      await db.systemConfig.upsert({
        where: { config_key: configKey },
        update: {
          config_value: JSON.stringify(newValue),
          updated_at: new Date()
        },
        create: {
          config_key: configKey,
          config_value: JSON.stringify(newValue),
          is_active: true,
          created_at: new Date(),
          updated_at: new Date()
        }
      });

      // æ›´æ–°å†…å­˜é…ç½®
      this.set(configKey, newValue);

      console.log(`âœ… Config hot reloaded: ${configKey}`);
    } catch (error) {
      console.error(`âŒ Config hot reload failed for ${configKey}:`, error);
      throw error;
    }
  }
}
```

### é…ç½®æ–‡ä»¶æ¨¡æ¿

```yaml
# config/production.yml
server:
  port: 3001
  host: 0.0.0.0
  cors:
    enabled: true
    origins: 
      - "https://your-domain.com"

database:
  pool:
    min: 2
    max: 20
    idle_timeout: 30000
    acquire_timeout: 60000
  ssl:
    enabled: true
    reject_unauthorized: true

redis:
  cluster:
    enabled: false
  sentinel:
    enabled: false
  retry_attempts: 3
  retry_delay: 1000

telegram:
  webhook:
    enabled: true
    url: "https://your-domain.com/api/telegram/webhook"
    secret_token: "${TELEGRAM_WEBHOOK_SECRET}"
    max_connections: 100
    allowed_updates:
      - "message"
      - "callback_query"
      - "inline_query"
  
  rate_limit:
    messages_per_second: 30
    messages_per_minute: 20

tron:
  network: "mainnet"
  endpoints:
    primary: "https://api.trongrid.io"
    fallback: "https://api.tronstack.io"
  fee_limit: 150000000
  retry_attempts: 3

monitoring:
  health_check:
    interval: 60000
    timeout: 5000
  metrics:
    enabled: true
    port: 3002
  alerts:
    enabled: true
    webhook: "https://your-monitoring.com/webhook"

logging:
  level: "info"
  format: "json"
  rotation:
    max_size: "100m"
    max_files: 5
  destinations:
    - type: "file"
      path: "/var/log/app/app.log"
    - type: "console"
      format: "pretty"
```

## ğŸ³ Docker å®¹å™¨åŒ–

### Docker é…ç½®

```dockerfile
# Dockerfile
FROM node:18-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶åŒ…é…ç½®æ–‡ä»¶
COPY package*.json ./
COPY pnpm-lock.yaml ./

# å®‰è£… pnpm å¹¶å®‰è£…ä¾èµ–
RUN npm install -g pnpm
RUN pnpm install --frozen-lockfile

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN pnpm run build

# ç”Ÿäº§ç¯å¢ƒé•œåƒ
FROM node:18-alpine AS production

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶æ„å»ºç»“æœ
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package*.json ./
COPY --from=builder /app/prisma ./prisma

# åˆ›å»ºæ—¥å¿—ç›®å½•
RUN mkdir -p /app/logs && chown nodejs:nodejs /app/logs

# åˆ‡æ¢åˆ°åº”ç”¨ç”¨æˆ·
USER nodejs

# æš´éœ²ç«¯å£
EXPOSE 3001

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node dist/health-check.js

# å¯åŠ¨åº”ç”¨
CMD ["node", "dist/index.js"]
```

### Docker Compose é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build:
      context: .
      target: production
    container_name: tron-energy-bot
    restart: unless-stopped
    ports:
      - "3001:3001"
      - "3002:3002"  # metrics port
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@postgres:5432/tron_energy_rental
      - REDIS_URL=redis://redis:6379
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs:rw
      - ./backups:/app/backups:rw
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  postgres:
    image: postgres:15-alpine
    container_name: tron-energy-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=tron_energy_rental
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data:rw
      - ./migrations:/docker-entrypoint-initdb.d:ro
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d tron_energy_rental"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  redis:
    image: redis:7-alpine
    container_name: tron-energy-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data:rw
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  nginx:
    image: nginx:alpine
    container_name: tron-energy-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx:rw
    depends_on:
      - app
    networks:
      - app-network

  prometheus:
    image: prom/prometheus:latest
    container_name: tron-energy-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus:rw
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - app-network

  grafana:
    image: grafana/grafana:latest
    container_name: tron-energy-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana:rw
      - ./monitoring/grafana:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
    networks:
      - app-network

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  app-network:
    driver: bridge
```

### Nginx é…ç½®

```nginx
# nginx/nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream app {
        server app:3001;
    }

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_conn_zone $binary_remote_addr zone=conn:10m;

    # SSL é…ç½®
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!MD5:!DSS;

    # HTTP é‡å®šå‘åˆ° HTTPS
    server {
        listen 80;
        server_name your-domain.com;
        return 301 https://$server_name$request_uri;
    }

    # HTTPS ä¸»æœåŠ¡å™¨
    server {
        listen 443 ssl http2;
        server_name your-domain.com;

        # å®‰å…¨å¤´
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";

        # API è·¯ç”±
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            limit_conn conn 10;
            
            proxy_pass http://app;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            proxy_pass http://app/health;
            access_log off;
        }

        # é™æ€æ–‡ä»¶
        location /static/ {
            alias /var/www/static/;
            expires 30d;
            add_header Cache-Control "public, immutable";
        }
    }
}
```

## ğŸš€ CI/CD è‡ªåŠ¨åŒ–

### GitHub Actions é…ç½®

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run lints
        run: npm run lint

      - name: Run tests
        run: npm run test
        env:
          DATABASE_URL: postgresql://postgres:test@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379

      - name: Run integration tests
        run: npm run test:integration
        env:
          DATABASE_URL: postgresql://postgres:test@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379

  build:
    needs: test
    runs-on: ubuntu-latest
    outputs:
      image: ${{ steps.image.outputs.image }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}

      - name: Output image
        id: image
        run: echo "image=${{ steps.meta.outputs.tags }}" >> $GITHUB_OUTPUT

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to server
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            # å¤‡ä»½å½“å‰ç‰ˆæœ¬
            cd /opt/tron-energy-rental
            ./scripts/backup.sh

            # æ›´æ–°ä»£ç 
            git pull origin main

            # æ›´æ–°ç¯å¢ƒå˜é‡
            echo "IMAGE_TAG=${{ needs.build.outputs.image }}" > .env.deploy

            # éƒ¨ç½²æ–°ç‰ˆæœ¬
            docker-compose -f docker-compose.prod.yml pull
            docker-compose -f docker-compose.prod.yml up -d

            # å¥åº·æ£€æŸ¥
            sleep 30
            curl -f http://localhost:3001/health || exit 1

            # æ¸…ç†æ—§é•œåƒ
            docker image prune -f

      - name: Notify deployment
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

### éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

echo "ğŸš€ Starting deployment..."

# é…ç½®
COMPOSE_FILE="docker-compose.prod.yml"
BACKUP_DIR="./backups/$(date +%Y%m%d_%H%M%S)"
HEALTH_CHECK_URL="http://localhost:3001/health"
MAX_RETRY=30
RETRY_INTERVAL=10

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# å¤‡ä»½æ•°æ®åº“
echo "ğŸ“Š Creating database backup..."
docker-compose -f $COMPOSE_FILE exec -T postgres pg_dump \
  -U postgres tron_energy_rental > "$BACKUP_DIR/database.sql"

# å¤‡ä»½é…ç½®æ–‡ä»¶
echo "âš™ï¸ Backing up configuration..."
cp .env "$BACKUP_DIR/.env.backup"
cp docker-compose.prod.yml "$BACKUP_DIR/docker-compose.backup.yml"

# æ‹‰å–æœ€æ–°é•œåƒ
echo "ğŸ“¥ Pulling latest images..."
docker-compose -f $COMPOSE_FILE pull

# åœæ­¢æœåŠ¡ï¼ˆä¿æŒæ•°æ®åº“è¿è¡Œï¼‰
echo "ğŸ›‘ Stopping application services..."
docker-compose -f $COMPOSE_FILE stop app nginx

# è¿è¡Œæ•°æ®åº“è¿ç§»
echo "ğŸ—„ï¸ Running database migrations..."
docker-compose -f $COMPOSE_FILE run --rm app npm run db:migrate

# å¯åŠ¨æ–°ç‰ˆæœ¬
echo "ğŸš€ Starting new version..."
docker-compose -f $COMPOSE_FILE up -d

# å¥åº·æ£€æŸ¥
echo "ğŸ¥ Performing health check..."
for i in $(seq 1 $MAX_RETRY); do
  if curl -f $HEALTH_CHECK_URL > /dev/null 2>&1; then
    echo "âœ… Health check passed!"
    break
  fi
  
  if [ $i -eq $MAX_RETRY ]; then
    echo "âŒ Health check failed after $MAX_RETRY attempts"
    
    # å›æ»š
    echo "ğŸ”„ Rolling back..."
    docker-compose -f $COMPOSE_FILE down
    
    # æ¢å¤æ•°æ®åº“
    docker-compose -f $COMPOSE_FILE exec -T postgres psql \
      -U postgres -d tron_energy_rental < "$BACKUP_DIR/database.sql"
    
    exit 1
  fi
  
  echo "â³ Health check attempt $i/$MAX_RETRY failed, retrying in ${RETRY_INTERVAL}s..."
  sleep $RETRY_INTERVAL
done

# æ¸…ç†
echo "ğŸ§¹ Cleaning up old images..."
docker image prune -f

# å‘é€é€šçŸ¥
echo "ğŸ“§ Sending deployment notification..."
curl -X POST $SLACK_WEBHOOK_URL \
  -H 'Content-type: application/json' \
  --data "{\"text\":\"âœ… Deployment completed successfully at $(date)\"}"

echo "ğŸ‰ Deployment completed successfully!"
```

## âš–ï¸ è´Ÿè½½å‡è¡¡å’Œæ‰©å±•

### è´Ÿè½½å‡è¡¡é…ç½®

```yaml
# docker-compose.scale.yml
version: '3.8'

services:
  app:
    build: .
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
      restart_policy:
        condition: on-failure
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
    environment:
      - NODE_ENV=production
      - INSTANCE_ID={{.Task.Slot}}
    volumes:
      - ./logs:/app/logs:rw
    networks:
      - app-network

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx-lb.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    networks:
      - app-network
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
```

### Nginx è´Ÿè½½å‡è¡¡é…ç½®

```nginx
# nginx/nginx-lb.conf
upstream app_servers {
    # è´Ÿè½½å‡è¡¡ç­–ç•¥
    least_conn;
    
    # åº”ç”¨æœåŠ¡å™¨
    server app_1:3001 weight=1 max_fails=3 fail_timeout=30s;
    server app_2:3001 weight=1 max_fails=3 fail_timeout=30s;
    server app_3:3001 weight=1 max_fails=3 fail_timeout=30s;
    
    # å¥åº·æ£€æŸ¥
    keepalive 32;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;

    location / {
        proxy_pass http://app_servers;
        
        # è´Ÿè½½å‡è¡¡é…ç½®
        proxy_next_upstream error timeout http_500 http_502 http_503;
        proxy_next_upstream_tries 3;
        proxy_next_upstream_timeout 10s;
        
        # è¿æ¥é…ç½®
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # ä¼šè¯ä¿æŒï¼ˆå¦‚æœéœ€è¦ï¼‰
        # ip_hash;
    }
}
```

### æ°´å¹³æ‰©å±•è„šæœ¬

```bash
#!/bin/bash
# scripts/scale.sh

COMPOSE_FILE="docker-compose.scale.yml"
SERVICE_NAME="app"

# è·å–å½“å‰å‰¯æœ¬æ•°
current_replicas=$(docker service ls --filter name=${SERVICE_NAME} --format "{{.Replicas}}" | cut -d'/' -f2)

echo "ğŸ“Š Current replicas: $current_replicas"

# æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½
load_avg=$(uptime | awk '{print $(NF-2)}' | sed 's/,//')
cpu_threshold=0.8
memory_usage=$(free | grep Mem | awk '{printf "%.2f", $3/$2}')
memory_threshold=0.8

echo "ğŸ’» Load average: $load_avg"
echo "ğŸ§  Memory usage: $memory_usage"

# è‡ªåŠ¨æ‰©å±•é€»è¾‘
if (( $(echo "$load_avg > $cpu_threshold" | bc -l) )) || 
   (( $(echo "$memory_usage > $memory_threshold" | bc -l) )); then
    
    new_replicas=$((current_replicas + 1))
    max_replicas=5
    
    if [ $new_replicas -le $max_replicas ]; then
        echo "ğŸ“ˆ Scaling up to $new_replicas replicas..."
        docker service scale ${SERVICE_NAME}=$new_replicas
        
        # ç­‰å¾…æ‰©å±•å®Œæˆ
        sleep 30
        
        # éªŒè¯æ‰©å±•ç»“æœ
        ./scripts/health-check.sh
        
        echo "âœ… Scale up completed!"
    else
        echo "âš ï¸ Maximum replicas ($max_replicas) reached"
    fi
    
elif (( $(echo "$load_avg < 0.3" | bc -l) )) && 
     (( $(echo "$memory_usage < 0.4" | bc -l) )) && 
     [ $current_replicas -gt 1 ]; then
    
    new_replicas=$((current_replicas - 1))
    
    echo "ğŸ“‰ Scaling down to $new_replicas replicas..."
    docker service scale ${SERVICE_NAME}=$new_replicas
    
    sleep 30
    ./scripts/health-check.sh
    
    echo "âœ… Scale down completed!"
else
    echo "ğŸ‘Œ No scaling needed"
fi
```

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦

### Prometheus é…ç½®

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alerts/*.yml"

scrape_configs:
  # åº”ç”¨æŒ‡æ ‡
  - job_name: 'tron-energy-bot'
    static_configs:
      - targets: ['app:3002']
    metrics_path: /metrics
    scrape_interval: 10s

  # ç³»ç»ŸæŒ‡æ ‡
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # æ•°æ®åº“æŒ‡æ ‡
  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis æŒ‡æ ‡
  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Nginx æŒ‡æ ‡
  - job_name: 'nginx-exporter'
    static_configs:
      - targets: ['nginx-exporter:9113']

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']
```

### å‘Šè­¦è§„åˆ™

```yaml
# monitoring/alerts/app.yml
groups:
  - name: application
    rules:
      # åº”ç”¨å¥åº·çŠ¶æ€
      - alert: ApplicationDown
        expr: up{job="tron-energy-bot"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Application instance is down"
          description: "{{ $labels.instance }} has been down for more than 1 minute"

      # é«˜é”™è¯¯ç‡
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} requests per second"

      # å“åº”æ—¶é—´è¿‡é•¿
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time"
          description: "95th percentile response time is {{ $value }} seconds"

      # å†…å­˜ä½¿ç”¨è¿‡é«˜
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }}"

      # CPU ä½¿ç”¨è¿‡é«˜
      - alert: HighCpuUsage
        expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value }}%"

  - name: business
    rules:
      # æ”¯ä»˜å¤±è´¥ç‡è¿‡é«˜
      - alert: HighPaymentFailureRate
        expr: rate(payment_failures_total[10m]) / rate(payment_attempts_total[10m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High payment failure rate"
          description: "Payment failure rate is {{ $value | humanizePercentage }}"

      # TRON ç½‘ç»œè¿æ¥å¼‚å¸¸
      - alert: TronNetworkDown
        expr: tron_network_connection_status == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "TRON network connection is down"
          description: "Cannot connect to TRON network"

      # é˜Ÿåˆ—ç§¯å‹è¿‡å¤š
      - alert: HighQueueLength
        expr: queue_length > 1000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High queue length"
          description: "Queue length is {{ $value }}"
```

### Grafana é¢æ¿é…ç½®

```json
{
  "dashboard": {
    "title": "TRON Energy Bot Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Active Users",
        "type": "stat",
        "targets": [
          {
            "expr": "active_users_count",
            "legendFormat": "Active Users"
          }
        ]
      },
      {
        "title": "Orders per Hour",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(orders_total[1h]) * 3600",
            "legendFormat": "Orders/hour"
          }
        ]
      }
    ]
  }
}
```

## ğŸ’¾ å¤‡ä»½å’Œæ¢å¤

### è‡ªåŠ¨å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# scripts/backup.sh

set -e

# é…ç½®
BACKUP_DIR="/opt/backups"
DB_NAME="tron_energy_rental"
DB_USER="postgres"
RETENTION_DAYS=30
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR/database"
mkdir -p "$BACKUP_DIR/config"
mkdir -p "$BACKUP_DIR/logs"

echo "ğŸ—„ï¸ Starting backup process..."

# æ•°æ®åº“å¤‡ä»½
echo "ğŸ“Š Backing up database..."
docker-compose exec -T postgres pg_dump \
  -U $DB_USER \
  -h localhost \
  --verbose \
  --clean \
  --no-owner \
  --no-privileges \
  $DB_NAME > "$BACKUP_DIR/database/db_backup_${TIMESTAMP}.sql"

# å‹ç¼©æ•°æ®åº“å¤‡ä»½
gzip "$BACKUP_DIR/database/db_backup_${TIMESTAMP}.sql"

# é…ç½®æ–‡ä»¶å¤‡ä»½
echo "âš™ï¸ Backing up configuration..."
cp .env "$BACKUP_DIR/config/env_backup_${TIMESTAMP}.env"
cp docker-compose*.yml "$BACKUP_DIR/config/" 2>/dev/null || true

# æ—¥å¿—å¤‡ä»½
echo "ğŸ“ Backing up logs..."
if [ -d "logs" ]; then
  tar -czf "$BACKUP_DIR/logs/logs_backup_${TIMESTAMP}.tar.gz" logs/
fi

# æ¸…ç†æ—§å¤‡ä»½
echo "ğŸ§¹ Cleaning up old backups..."
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete
find "$BACKUP_DIR" -name "*.env" -mtime +$RETENTION_DAYS -delete
find "$BACKUP_DIR" -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete

# å¤‡ä»½åˆ°äº‘å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
if [ -n "$AWS_S3_BUCKET" ]; then
  echo "â˜ï¸ Uploading to S3..."
  aws s3 cp "$BACKUP_DIR/database/db_backup_${TIMESTAMP}.sql.gz" \
    "s3://$AWS_S3_BUCKET/backups/database/"
fi

# éªŒè¯å¤‡ä»½
echo "âœ… Verifying backup..."
gunzip -t "$BACKUP_DIR/database/db_backup_${TIMESTAMP}.sql.gz"

echo "ğŸ‰ Backup completed successfully!"
echo "ğŸ“ Backup location: $BACKUP_DIR"
echo "ğŸ“Š Database backup: db_backup_${TIMESTAMP}.sql.gz"
```

### æ¢å¤è„šæœ¬

```bash
#!/bin/bash
# scripts/restore.sh

set -e

if [ -z "$1" ]; then
  echo "Usage: $0 <backup_file>"
  echo "Available backups:"
  ls -la /opt/backups/database/
  exit 1
fi

BACKUP_FILE="$1"
DB_NAME="tron_energy_rental"
DB_USER="postgres"

echo "ğŸ”„ Starting restore process..."
echo "ğŸ“ Backup file: $BACKUP_FILE"

# ç¡®è®¤æ“ä½œ
read -p "âš ï¸ This will overwrite the current database. Continue? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
  echo "âŒ Restore cancelled"
  exit 1
fi

# åœæ­¢åº”ç”¨
echo "ğŸ›‘ Stopping application..."
docker-compose stop app

# åˆ›å»ºå½“å‰æ•°æ®åº“å¤‡ä»½
echo "ğŸ’¾ Creating safety backup..."
SAFETY_BACKUP="/tmp/safety_backup_$(date +%Y%m%d_%H%M%S).sql"
docker-compose exec -T postgres pg_dump \
  -U $DB_USER $DB_NAME > "$SAFETY_BACKUP"

# è§£å‹å¤‡ä»½æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
if [[ "$BACKUP_FILE" == *.gz ]]; then
  echo "ğŸ“¦ Decompressing backup..."
  gunzip -c "$BACKUP_FILE" > "/tmp/restore_temp.sql"
  RESTORE_FILE="/tmp/restore_temp.sql"
else
  RESTORE_FILE="$BACKUP_FILE"
fi

# æ¢å¤æ•°æ®åº“
echo "ğŸ“Š Restoring database..."
docker-compose exec -T postgres psql \
  -U $DB_USER \
  -d $DB_NAME \
  < "$RESTORE_FILE"

# è¿è¡Œæ•°æ®åº“è¿ç§»ï¼ˆå¦‚æœéœ€è¦ï¼‰
echo "ğŸ—„ï¸ Running migrations..."
docker-compose run --rm app npm run db:migrate

# å¯åŠ¨åº”ç”¨
echo "ğŸš€ Starting application..."
docker-compose start app

# å¥åº·æ£€æŸ¥
echo "ğŸ¥ Performing health check..."
sleep 30
if curl -f http://localhost:3001/health > /dev/null 2>&1; then
  echo "âœ… Restore completed successfully!"
  
  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
  rm -f "$RESTORE_FILE" 2>/dev/null
  
  echo "ğŸ’¡ Safety backup saved at: $SAFETY_BACKUP"
else
  echo "âŒ Health check failed!"
  echo "ğŸ”„ Consider rolling back using: $SAFETY_BACKUP"
  exit 1
fi
```

## ğŸ’¡ è¿ç»´æœ€ä½³å®è·µ

### æ€§èƒ½ä¼˜åŒ–æ¸…å•

```typescript
// utils/performance.ts
export class PerformanceOptimizer {
  /**
   * æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–
   */
  static async optimizeQueries(): Promise<void> {
    // æ·»åŠ ç¼ºå¤±çš„ç´¢å¼•
    await db.$executeRaw`
      CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_telegram_id 
      ON users(telegram_id);
    `;
    
    await db.$executeRaw`
      CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_orders_user_status 
      ON orders(user_id, status) WHERE status IN ('pending', 'processing');
    `;
    
    // åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
    await db.$executeRaw`ANALYZE;`;
  }

  /**
   * è¿æ¥æ± ä¼˜åŒ–
   */
  static configureConnectionPool(): void {
    const poolConfig = {
      max: parseInt(process.env.DB_POOL_MAX || '20'),
      min: parseInt(process.env.DB_POOL_MIN || '2'),
      acquire: parseInt(process.env.DB_POOL_ACQUIRE_TIMEOUT || '60000'),
      idle: parseInt(process.env.DB_POOL_IDLE_TIMEOUT || '30000'),
      evict: parseInt(process.env.DB_POOL_EVICT_INTERVAL || '10000')
    };
    
    console.log('Database pool configuration:', poolConfig);
  }

  /**
   * å†…å­˜ä½¿ç”¨ä¼˜åŒ–
   */
  static monitorMemoryUsage(): void {
    setInterval(() => {
      const usage = process.memoryUsage();
      const usageInMB = {
        rss: Math.round(usage.rss / 1024 / 1024),
        heapTotal: Math.round(usage.heapTotal / 1024 / 1024),
        heapUsed: Math.round(usage.heapUsed / 1024 / 1024),
        external: Math.round(usage.external / 1024 / 1024)
      };
      
      if (usageInMB.heapUsed > 400) { // 400MB é˜ˆå€¼
        console.warn('ğŸš¨ High memory usage:', usageInMB);
        
        // è§¦å‘åƒåœ¾å›æ”¶
        if (global.gc) {
          global.gc();
        }
      }
    }, 60000); // æ¯åˆ†é’Ÿæ£€æŸ¥
  }
}
```

### å®‰å…¨é…ç½®æ£€æŸ¥

```typescript
// utils/security.ts
export class SecurityValidator {
  /**
   * å®‰å…¨é…ç½®æ£€æŸ¥
   */
  static async validateSecurityConfig(): Promise<{
    passed: boolean;
    issues: string[];
  }> {
    const issues: string[] = [];

    // æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
    const requiredSecrets = [
      'JWT_SECRET',
      'ENCRYPTION_KEY',
      'TELEGRAM_WEBHOOK_SECRET',
      'DB_PASSWORD'
    ];

    for (const secret of requiredSecrets) {
      if (!process.env[secret]) {
        issues.push(`Missing required secret: ${secret}`);
      } else if (process.env[secret].length < 32) {
        issues.push(`Weak secret: ${secret} (should be at least 32 characters)`);
      }
    }

    // æ£€æŸ¥ç”Ÿäº§ç¯å¢ƒé…ç½®
    if (process.env.NODE_ENV === 'production') {
      if (process.env.TELEGRAM_WEBHOOK_URL?.startsWith('http://')) {
        issues.push('Webhook URL should use HTTPS in production');
      }

      if (!process.env.SSL_CERT || !process.env.SSL_KEY) {
        issues.push('SSL certificates not configured for production');
      }
    }

    // æ£€æŸ¥æ•°æ®åº“è¿æ¥å®‰å…¨æ€§
    const dbUrl = process.env.DATABASE_URL;
    if (dbUrl && !dbUrl.includes('sslmode=require') && process.env.NODE_ENV === 'production') {
      issues.push('Database connection should require SSL in production');
    }

    return {
      passed: issues.length === 0,
      issues
    };
  }

  /**
   * è¿è¡Œæ—¶å®‰å…¨æ£€æŸ¥
   */
  static async performRuntimeSecurityCheck(): Promise<void> {
    // æ£€æŸ¥æ–‡ä»¶æƒé™
    const sensitiveFiles = ['.env', 'keys/', 'certs/'];
    
    for (const file of sensitiveFiles) {
      if (await this.checkFilePermissions(file)) {
        console.warn(`âš ï¸ Insecure file permissions: ${file}`);
      }
    }

    // æ£€æŸ¥å¼€æ”¾ç«¯å£
    await this.checkOpenPorts();

    // æ£€æŸ¥ä¾èµ–æ¼æ´
    await this.checkDependencyVulnerabilities();
  }

  private static async checkFilePermissions(filepath: string): Promise<boolean> {
    try {
      const stats = require('fs').statSync(filepath);
      const mode = stats.mode & parseInt('777', 8);
      return mode > parseInt('600', 8); // åº”è¯¥åªæœ‰æ‰€æœ‰è€…å¯è¯»å†™
    } catch {
      return false; // æ–‡ä»¶ä¸å­˜åœ¨
    }
  }
}
```

### è¿ç»´ä»»åŠ¡è‡ªåŠ¨åŒ–

```bash
#!/bin/bash
# scripts/maintenance.sh

# æ¯æ—¥ç»´æŠ¤ä»»åŠ¡
daily_maintenance() {
  echo "ğŸ—“ï¸ Running daily maintenance..."
  
  # æ•°æ®åº“ç»´æŠ¤
  docker-compose exec postgres psql -U postgres -d tron_energy_rental -c "
    VACUUM ANALYZE;
    REINDEX DATABASE tron_energy_rental;
  "
  
  # æ¸…ç†è¿‡æœŸæ•°æ®
  docker-compose exec app npm run cleanup:expired-orders
  docker-compose exec app npm run cleanup:old-logs
  
  # å¤‡ä»½
  ./scripts/backup.sh
  
  # ç”ŸæˆæŠ¥å‘Š
  ./scripts/generate-report.sh daily
  
  echo "âœ… Daily maintenance completed"
}

# æ¯å‘¨ç»´æŠ¤ä»»åŠ¡
weekly_maintenance() {
  echo "ğŸ“… Running weekly maintenance..."
  
  # æ·±åº¦æ•°æ®åº“æ¸…ç†
  docker-compose exec postgres psql -U postgres -d tron_energy_rental -c "
    VACUUM FULL;
    CLUSTER;
  "
  
  # æ›´æ–°ä¾èµ–
  docker-compose exec app npm audit fix
  
  # å®‰å…¨æ‰«æ
  docker-compose exec app npm audit --audit-level=moderate
  
  # ç”Ÿæˆå‘¨æŠ¥
  ./scripts/generate-report.sh weekly
  
  echo "âœ… Weekly maintenance completed"
}

# æ ¹æ®å‚æ•°æ‰§è¡Œå¯¹åº”ä»»åŠ¡
case "$1" in
  "daily")
    daily_maintenance
    ;;
  "weekly")
    weekly_maintenance
    ;;
  *)
    echo "Usage: $0 {daily|weekly}"
    exit 1
    ;;
esac
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [Error Handling](./10-error-handling.md) - é”™è¯¯å¤„ç†å’Œç›‘æ§
- [Project Examples](./12-project-examples.md) - å®Œæ•´éƒ¨ç½²ç¤ºä¾‹
- [README](./README.md) - å®Œæ•´æ–‡æ¡£å¯¼èˆª

---

> ğŸ’¡ **è¿ç»´å»ºè®®**
> 
> 1. **è‡ªåŠ¨åŒ–ä¼˜å…ˆ** - å°½å¯èƒ½è‡ªåŠ¨åŒ–éƒ¨ç½²ã€ç›‘æ§å’Œç»´æŠ¤ä»»åŠ¡
> 2. **ç›‘æ§å…¨è¦†ç›–** - ä»åŸºç¡€è®¾æ–½åˆ°ä¸šåŠ¡æŒ‡æ ‡çš„å…¨æ–¹ä½ç›‘æ§
> 3. **å®‰å…¨ç¬¬ä¸€** - å®šæœŸè¿›è¡Œå®‰å…¨å®¡è®¡å’Œæ¼æ´æ‰«æ
> 4. **æ–‡æ¡£åŒæ­¥** - ä¿æŒéƒ¨ç½²æ–‡æ¡£ä¸å®é™…ç¯å¢ƒçš„ä¸€è‡´æ€§
> 5. **æ¼”ç»ƒéªŒè¯** - å®šæœŸè¿›è¡Œæ•…éšœæ¢å¤æ¼”ç»ƒ
